# Комментарий к статье "LLM Firewall"

Ильнур, отличная статья! Особенно понравилось что привязали всё к конкретным пунктам ФСТЭК №117 — это редкость.

Добавлю пару мыслей из своего опыта.

По поводу "LLM as a judge не панацея" — полностью согласен. Я пришёл к многоуровневой архитектуре: сначала быстрые rule-based фильтры (меньше 5ms), потом ML-классификаторы на эмбеддингах (~30ms), и только в спорных случаях LLM (~200ms). То есть LLM — последняя инстанция, а не первая линия.

К таксономии атак хотел бы добавить несколько актуальных векторов 2025 года, которых в статье не увидел:

- Echo Chamber — накопление контекста в multi-turn диалогах для обхода guardrails
- Memory Poisoning (OWASP ASI04) — атаки на persistent memory агентов
- Tool Hijacking (OWASP ASI05) — перехват function calling в MCP/A2A протоколах
- CVE-2025-68664 (LangGrinch) — pickle десериализация в LangChain

Про телеметрию — классная идея! Я использую похожий подход: анализирую entropy логитов как индикатор jailbreak, смотрю на attention patterns. Даёт хорошие результаты при минимальной latency.

Если интересно посмотреть на практическую реализацию — у меня есть open-source проект SENTINEL с 200 detection engines (pip install sentinel-llm-security). Архитектура похожа на вашу: Go Gateway + Python Brain через gRPC.

GitHub: https://github.com/DmitrL-dev/AISecurity

Буду рад обсудить детали!
