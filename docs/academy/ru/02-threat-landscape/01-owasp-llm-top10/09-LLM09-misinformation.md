# LLM09: Misinformation

> **–£—Ä–æ–≤–µ–Ω—å:** Õ‡˜ËÌ‡˛˘ËÈ  
> **–í—Ä–µ–º—è:** 35 –º–∏–Ω—É—Ç  
> **–¢—Ä–µ–∫:** 02 ‚Äî Threat Landscape  
> **–ú–æ–¥—É–ª—å:** 02.1 ‚Äî OWASP LLM Top 10  
> **–í–µ—Ä—Å–∏—è:** 1.0

---

## –¶–µ–ª–∏ –æ–±—É—á–µ–Ω–∏—è

- [ ] –ü–æ–Ω—è—Ç—å —Ä–∏—Å–∫–∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ misinformation LLM
- [ ] –ò–∑—É—á–∏—Ç—å —Ç–∏–ø—ã –∏ –ø—Ä–∏—á–∏–Ω—ã hallucinations
- [ ] –û—Å–≤–æ–∏—Ç—å –º–µ—Ç–æ–¥—ã –¥–µ—Ç–µ–∫—Ç–∏—Ä–æ–≤–∞–Ω–∏—è –∏ –º–∏—Ç–∏–≥–∞—Ü–∏–∏
- [ ] –ò–Ω—Ç–µ–≥—Ä–∏—Ä–æ–≤–∞—Ç—å fact-checking –≤ SENTINEL

---

## 1. –ü—Ä–æ–±–ª–µ–º–∞ Misinformation

### 1.1 –ß—Ç–æ —Ç–∞–∫–æ–µ Misinformation –≤ LLM?

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                  LLM MISINFORMATION TYPES                          ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ                                                                    ‚îÇ
‚îÇ  HALLUCINATIONS:                                                   ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ LLM "–≤—ã–¥—É–º—ã–≤–∞–µ—Ç" —Ñ–∞–∫—Ç—ã, –∫–æ—Ç–æ—Ä—ã—Ö –Ω–µ—Ç                          ‚îÇ
‚îÇ      ‚Ä¢ Fake citations                                              ‚îÇ
‚îÇ      ‚Ä¢ Invented people/events                                      ‚îÇ
‚îÇ      ‚Ä¢ Wrong but confident answers                                 ‚îÇ
‚îÇ                                                                    ‚îÇ
‚îÇ  FACTUAL ERRORS:                                                   ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ –ù–µ–≤–µ—Ä–Ω–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –∏–∑ training data                         ‚îÇ
‚îÇ      ‚Ä¢ Outdated facts                                              ‚îÇ
‚îÇ      ‚Ä¢ Incorrect statistics                                        ‚îÇ
‚îÇ      ‚Ä¢ Confused entities                                           ‚îÇ
‚îÇ                                                                    ‚îÇ
‚îÇ  MALICIOUS GENERATION:                                             ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ –ù–∞–º–µ—Ä–µ–Ω–Ω–æ–µ —Å–æ–∑–¥–∞–Ω–∏–µ –¥–µ–∑–∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏                            ‚îÇ
‚îÇ      ‚Ä¢ Propaganda                                                  ‚îÇ
‚îÇ      ‚Ä¢ Fake news                                                   ‚îÇ
‚îÇ      ‚Ä¢ Deepfakes (text)                                            ‚îÇ
‚îÇ                                                                    ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

### 1.2 –ü–æ—á–µ–º—É LLM Hallucinate?

| –ü—Ä–∏—á–∏–Ω–∞ | –û–ø–∏—Å–∞–Ω–∏–µ | –ü—Ä–∏–º–µ—Ä |
|---------|----------|--------|
| **Statistical patterns** | LLM –ø—Ä–µ–¥—Å–∫–∞–∑—ã–≤–∞–µ—Ç "–≤–µ—Ä–æ—è—Ç–Ω—ã–µ" —Å–ª–æ–≤–∞ | "The capital of Australia is Sydney" |
| **Knowledge cutoff** | –ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –ø–æ—Å–ª–µ –¥–∞—Ç—ã –æ–±—É—á–µ–Ω–∏—è | Outdated CEO names |
| **Rare topics** | –ú–∞–ª–æ training data | Obscure historical events |
| **Ambiguity** | –ù–µ–æ–¥–Ω–æ–∑–Ω–∞—á–Ω—ã–π –∫–æ–Ω—Ç–µ–∫—Å—Ç | Wrong "John Smith" |
| **Overconfidence** | –£–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å –±–µ–∑ –æ—Å–Ω–æ–≤–∞–Ω–∏–π | Invented citations |

---

## 2. –¢–∏–ø—ã Hallucinations

### 2.1 –ö–∞—Ç–µ–≥–æ—Ä–∏–∏

```python
class HallucinationType:
    """–¢–∏–ø—ã hallucinations"""
    
    CATEGORIES = {
        'factual': {
            'description': '–ù–µ–≤–µ—Ä–Ω—ã–µ —Ñ–∞–∫—Ç—ã –æ —Ä–µ–∞–ª—å–Ω–æ–º –º–∏—Ä–µ',
            'examples': [
                'Wrong dates/numbers',
                'Incorrect attributions',
                'False historical claims'
            ],
            'severity': 'high'
        },
        
        'intrinsic': {
            'description': '–ü—Ä–æ—Ç–∏–≤–æ—Ä–µ—á–∏–µ —Å –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª–µ–Ω–Ω—ã–º –∫–æ–Ω—Ç–µ–∫—Å—Ç–æ–º',
            'examples': [
                'Summarizing with wrong details',
                'Answering beyond the document',
                'Mixing up entities in text'
            ],
            'severity': 'high'
        },
        
        'extrinsic': {
            'description': '–ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –Ω–µ –≤ –∫–æ–Ω—Ç–µ–∫—Å—Ç–µ –∏ –Ω–µ verifiable',
            'examples': [
                'Adding plausible but unverified details',
                'Invented quotes',
                'Made-up sources'
            ],
            'severity': 'medium'
        },
        
        'coherence': {
            'description': '–õ–æ–≥–∏—á–µ—Å–∫–∏ –Ω–µ—Å–æ–≤–º–µ—Å—Ç–∏–º—ã–µ —É—Ç–≤–µ—Ä–∂–¥–µ–Ω–∏—è',
            'examples': [
                'Self-contradicting statements',
                'Impossible scenarios',
                'Logical fallacies'
            ],
            'severity': 'medium'
        }
    }
```

### 2.2 –†–µ–∞–ª—å–Ω—ã–µ –ü—Ä–∏–º–µ—Ä—ã

```python
# –ó–∞–¥–æ–∫—É–º–µ–Ω—Ç–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ —Å–ª—É—á–∞–∏ hallucinations

real_world_examples = [
    {
        'case': 'Lawyer uses ChatGPT (2023)',
        'description': '–ê–¥–≤–æ–∫–∞—Ç –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–ª ChatGPT –¥–ª—è research –∏ –ø–æ–¥–∞–ª –∏—Å–∫ —Å–æ —Å—Å—ã–ª–∫–∞–º–∏ –Ω–∞ 6 –Ω–µ—Å—É—â–µ—Å—Ç–≤—É—é—â–∏—Ö —Å—É–¥–µ–±–Ω—ã—Ö –¥–µ–ª',
        'fake_cases': [
            'Varghese v. China Southern Airlines',
            'Shaboon v. Egyptair',
            # ... –≤—Å–µ –≤—ã–¥—É–º–∞–Ω–Ω—ã–µ
        ],
        'consequence': 'Sanctions, public embarrassment',
        'lesson': 'Always verify AI-generated citations'
    },
    {
        'case': 'Google Bard launch (2023)',
        'description': '–ù–∞ –¥–µ–º–æ Bard –∑–∞—è–≤–∏–ª, —á—Ç–æ James Webb Telescope —Å–¥–µ–ª–∞–ª –ø–µ—Ä–≤—ã–µ —Ñ–æ—Ç–æ —ç–∫–∑–æ–ø–ª–∞–Ω–µ—Ç—ã, —á—Ç–æ –Ω–µ–≤–µ—Ä–Ω–æ',
        'consequence': '$100B market cap loss for Alphabet',
        'lesson': 'Verify even simple factual claims'
    },
    {
        'case': 'Air Canada chatbot (2024)',
        'description': 'Chatbot –¥–∞–ª –Ω–µ–≤–µ—Ä–Ω—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ bereavement policy, –∫–æ–º–ø–∞–Ω–∏—è –±—ã–ª–∞ –æ–±—è–∑–∞–Ω–∞ –≤—ã–ø–æ–ª–Ω–∏—Ç—å',
        'consequence': 'Financial loss, legal liability',
        'lesson': 'AI responses can be legally binding'
    }
]
```

---

## 3. –î–µ—Ç–µ–∫—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ Misinformation

### 3.1 Confidence Analysis

```python
class ConfidenceAnalyzer:
    """–ê–Ω–∞–ª–∏–∑ —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏ LLM"""
    
    def analyze_response(self, response: str, 
                         logprobs: list = None) -> dict:
        """–ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç response –Ω–∞ –ø—Ä–∏–∑–Ω–∞–∫–∏ –Ω–µ—É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏"""
        
        # –õ–∏–Ω–≥–≤–∏—Å—Ç–∏—á–µ—Å–∫–∏–µ –º–∞—Ä–∫–µ—Ä—ã –Ω–µ—É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏
        uncertainty_markers = [
            'I think', 'probably', 'maybe', 'might',
            'I believe', 'possibly', 'could be',
            'approximately', 'roughly', 'around'
        ]
        
        # –ú–∞—Ä–∫–µ—Ä—ã –≤—ã—Å–æ–∫–æ–π —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏ (–ø–æ—Ç–µ–Ω—Ü–∏–∞–ª—å–Ω–æ –æ–ø–∞—Å–Ω–æ)
        overconfidence_markers = [
            'definitely', 'certainly', 'absolutely',
            'without doubt', '100%', 'always', 'never'
        ]
        
        response_lower = response.lower()
        
        uncertainty_count = sum(
            1 for m in uncertainty_markers if m in response_lower
        )
        
        overconfidence_count = sum(
            1 for m in overconfidence_markers if m in response_lower
        )
        
        # –ê–Ω–∞–ª–∏–∑ logprobs –µ—Å–ª–∏ –¥–æ—Å—Ç—É–ø–Ω—ã
        token_confidence = None
        if logprobs:
            token_confidence = self._analyze_logprobs(logprobs)
        
        return {
            'uncertainty_markers': uncertainty_count,
            'overconfidence_markers': overconfidence_count,
            'token_confidence': token_confidence,
            'risk_assessment': self._assess_risk(
                uncertainty_count, overconfidence_count
            )
        }
    
    def _analyze_logprobs(self, logprobs: list) -> dict:
        """–ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç logprobs –¥–ª—è —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏"""
        
        import math
        
        # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º logprobs –≤ probabilities
        probs = [math.exp(lp) for lp in logprobs]
        
        avg_confidence = sum(probs) / len(probs)
        min_confidence = min(probs)
        
        # –ò—â–µ–º "uncertain" —Ç–æ–∫–µ–Ω—ã
        low_confidence_count = sum(1 for p in probs if p < 0.5)
        
        return {
            'average_confidence': avg_confidence,
            'min_confidence': min_confidence,
            'low_confidence_tokens': low_confidence_count,
            'total_tokens': len(probs)
        }
```

### 3.2 Fact Verification

```python
class FactVerifier:
    """–í–µ—Ä–∏—Ñ–∏–∫–∞—Ü–∏—è —Ñ–∞–∫—Ç–æ–≤ –≤ LLM output"""
    
    def __init__(self, knowledge_base=None, search_api=None):
        self.kb = knowledge_base
        self.search = search_api
    
    def verify_claims(self, response: str) -> dict:
        """–ò–∑–≤–ª–µ–∫–∞–µ—Ç –∏ –≤–µ—Ä–∏—Ñ–∏—Ü–∏—Ä—É–µ—Ç claims"""
        
        # 1. Extract claims
        claims = self._extract_claims(response)
        
        # 2. Verify each claim
        results = []
        for claim in claims:
            verification = self._verify_claim(claim)
            results.append({
                'claim': claim,
                'verified': verification['verified'],
                'confidence': verification['confidence'],
                'sources': verification['sources']
            })
        
        # 3. Overall assessment
        verified_count = sum(1 for r in results if r['verified'])
        
        return {
            'total_claims': len(claims),
            'verified_claims': verified_count,
            'verification_rate': verified_count / len(claims) if claims else 1,
            'details': results
        }
    
    def _extract_claims(self, text: str) -> list:
        """–ò–∑–≤–ª–µ–∫–∞–µ—Ç verifiable claims –∏–∑ —Ç–µ–∫—Å—Ç–∞"""
        
        # –ò—Å–ø–æ–ª—å–∑—É–µ–º NLP –¥–ª—è –∏–∑–≤–ª–µ—á–µ–Ω–∏—è —É—Ç–≤–µ—Ä–∂–¥–µ–Ω–∏–π
        claims = []
        
        # –ò—â–µ–º patterns —Å –¥–∞—Ç–∞–º–∏, —á–∏—Å–ª–∞–º–∏, –∏–º–µ–Ω–∞–º–∏
        import re
        
        # Dates
        date_pattern = r'in \d{4}|on [A-Z][a-z]+ \d{1,2}'
        # Numbers
        number_pattern = r'\d+(?:\.\d+)?(?:\s*%|million|billion)?'
        # Named entities (simplified)
        entity_pattern = r'[A-Z][a-z]+ [A-Z][a-z]+'
        
        sentences = text.split('.')
        for sentence in sentences:
            if (re.search(date_pattern, sentence) or 
                re.search(number_pattern, sentence) or
                re.search(entity_pattern, sentence)):
                claims.append(sentence.strip())
        
        return claims
    
    def _verify_claim(self, claim: str) -> dict:
        """–í–µ—Ä–∏—Ñ–∏—Ü–∏—Ä—É–µ—Ç –æ—Ç–¥–µ–ª—å–Ω—ã–π claim"""
        
        # 1. Check knowledge base
        if self.kb:
            kb_result = self.kb.query(claim)
            if kb_result['found']:
                return {
                    'verified': kb_result['matches'],
                    'confidence': kb_result['confidence'],
                    'sources': kb_result['sources']
                }
        
        # 2. Web search
        if self.search:
            search_results = self.search.query(claim)
            if search_results:
                return self._analyze_search_results(claim, search_results)
        
        return {
            'verified': None,
            'confidence': 0,
            'sources': []
        }
```

### 3.3 Citation Verification

```python
class CitationVerifier:
    """–í–µ—Ä–∏—Ñ–∏–∫–∞—Ü–∏—è —Ü–∏—Ç–∞—Ç –∏ —Å—Å—ã–ª–æ–∫"""
    
    def verify_citations(self, response: str) -> dict:
        """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç –≤—Å–µ citations –≤ response"""
        
        # Extract citations
        citations = self._extract_citations(response)
        
        results = []
        for citation in citations:
            verification = self._verify_citation(citation)
            results.append({
                'citation': citation,
                **verification
            })
        
        fake_count = sum(1 for r in results if r['status'] == 'fake')
        
        return {
            'total_citations': len(citations),
            'verified': sum(1 for r in results if r['status'] == 'verified'),
            'fake': fake_count,
            'unknown': sum(1 for r in results if r['status'] == 'unknown'),
            'details': results,
            'warning': fake_count > 0
        }
    
    def _extract_citations(self, text: str) -> list:
        """–ò–∑–≤–ª–µ–∫–∞–µ—Ç citations –∏–∑ —Ç–µ–∫—Å—Ç–∞"""
        
        import re
        
        citations = []
        
        # Academic style: (Author, Year)
        academic_pattern = r'\(([A-Z][a-z]+(?:\s+(?:et\s+al\.|&\s+[A-Z][a-z]+))?),?\s*(\d{4})\)'
        
        # URL style
        url_pattern = r'https?://[^\s]+'
        
        # Quote style
        quote_pattern = r'"([^"]+)"\s*[-‚Äì]\s*([A-Z][a-z]+ [A-Z][a-z]+)'
        
        for match in re.finditer(academic_pattern, text):
            citations.append({
                'type': 'academic',
                'author': match.group(1),
                'year': match.group(2),
                'raw': match.group(0)
            })
        
        for match in re.finditer(url_pattern, text):
            citations.append({
                'type': 'url',
                'url': match.group(0),
                'raw': match.group(0)
            })
        
        return citations
    
    def _verify_citation(self, citation: dict) -> dict:
        """–í–µ—Ä–∏—Ñ–∏—Ü–∏—Ä—É–µ—Ç –æ—Ç–¥–µ–ª—å–Ω—É—é citation"""
        
        if citation['type'] == 'url':
            return self._verify_url(citation['url'])
        
        elif citation['type'] == 'academic':
            return self._verify_academic(
                citation['author'],
                citation['year']
            )
        
        return {'status': 'unknown'}
    
    def _verify_url(self, url: str) -> dict:
        """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç —Å—É—â–µ—Å—Ç–≤–æ–≤–∞–Ω–∏–µ URL"""
        
        import requests
        
        try:
            response = requests.head(url, timeout=5)
            if response.status_code == 200:
                return {'status': 'verified', 'note': 'URL exists'}
            else:
                return {'status': 'fake', 'note': f'HTTP {response.status_code}'}
        except:
            return {'status': 'unknown', 'note': 'Could not verify'}
    
    def _verify_academic(self, author: str, year: str) -> dict:
        """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç –∞–∫–∞–¥–µ–º–∏—á–µ—Å–∫—É—é citation —á–µ—Ä–µ–∑ API"""
        
        # –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å CrossRef, Semantic Scholar, etc.
        # –£–ø—Ä–æ—â—ë–Ω–Ω–æ:
        
        search_query = f"{author} {year}"
        
        # API call would go here
        # result = semantic_scholar.search(search_query)
        
        return {'status': 'unknown', 'note': 'Verification pending'}
```

---

## 4. –ú–∏—Ç–∏–≥–∞—Ü–∏—è

### 4.1 Prompt Engineering

```python
class MisinformationMitigation:
    """–ú–µ—Ç–æ–¥—ã —Å–Ω–∏–∂–µ–Ω–∏—è misinformation"""
    
    def create_grounded_prompt(self, query: str, 
                                context: str = None) -> str:
        """–°–æ–∑–¥–∞—ë—Ç prompt, —Å–Ω–∏–∂–∞—é—â–∏–π hallucinations"""
        
        grounding_instructions = """
        IMPORTANT INSTRUCTIONS:
        
        1. Only provide information you are confident about
        2. If uncertain, say "I'm not sure" or "I don't have enough information"
        3. Distinguish between facts and opinions
        4. Do not invent citations or sources
        5. If asked about recent events, mention your knowledge cutoff
        6. Prefer "I don't know" over a potentially wrong answer
        """
        
        if context:
            # RAG-style: ground in provided context
            prompt = f"""
            {grounding_instructions}
            
            BASE YOUR ANSWER ON THIS CONTEXT ONLY:
            {context}
            
            If the context doesn't contain the answer, say so.
            
            QUESTION: {query}
            """
        else:
            prompt = f"""
            {grounding_instructions}
            
            QUESTION: {query}
            """
        
        return prompt
    
    def add_uncertainty_request(self, prompt: str) -> str:
        """–î–æ–±–∞–≤–ª—è–µ—Ç –∑–∞–ø—Ä–æ—Å –Ω–∞ –≤—ã—Ä–∞–∂–µ–Ω–∏–µ uncertainty"""
        
        return prompt + """
        
        ADDITIONAL REQUIREMENT:
        For each factual claim you make, indicate your confidence level:
        - [HIGH CONFIDENCE]: Well-established facts
        - [MEDIUM CONFIDENCE]: Likely true but verify
        - [LOW CONFIDENCE]: Uncertain, may need verification
        """
```

### 4.2 Output Processing

```python
class OutputProcessor:
    """–û–±—Ä–∞–±–æ—Ç–∫–∞ output –¥–ª—è mitigation"""
    
    def __init__(self):
        self.confidence_analyzer = ConfidenceAnalyzer()
        self.fact_verifier = FactVerifier()
        self.citation_verifier = CitationVerifier()
    
    def process_response(self, response: str) -> dict:
        """–ü–æ–ª–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ response"""
        
        # 1. Analyze confidence
        confidence = self.confidence_analyzer.analyze_response(response)
        
        # 2. Verify facts
        facts = self.fact_verifier.verify_claims(response)
        
        # 3. Verify citations
        citations = self.citation_verifier.verify_citations(response)
        
        # 4. Generate warnings
        warnings = self._generate_warnings(confidence, facts, citations)
        
        # 5. Create annotated response
        annotated = self._annotate_response(response, facts, citations)
        
        return {
            'original_response': response,
            'annotated_response': annotated,
            'confidence_analysis': confidence,
            'fact_verification': facts,
            'citation_verification': citations,
            'warnings': warnings,
            'overall_reliability': self._calculate_reliability(
                facts, citations
            )
        }
    
    def _generate_warnings(self, confidence, facts, citations) -> list:
        """–ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç warnings –¥–ª—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è"""
        
        warnings = []
        
        if confidence['overconfidence_markers'] > 2:
            warnings.append(
                "‚ö†Ô∏è Response shows high confidence - verify claims independently"
            )
        
        if facts['verification_rate'] < 0.5:
            warnings.append(
                "‚ö†Ô∏è Less than 50% of claims could be verified"
            )
        
        if citations['fake'] > 0:
            warnings.append(
                f"üö® {citations['fake']} potentially fake citation(s) detected"
            )
        
        return warnings
```

---

## 5. SENTINEL Integration

```python
class SENTINELMisinformationGuard:
    """SENTINEL –º–æ–¥—É–ª—å –∑–∞—â–∏—Ç—ã –æ—Ç misinformation"""
    
    def __init__(self):
        self.mitigation = MisinformationMitigation()
        self.processor = OutputProcessor()
    
    def protect_request(self, query: str, context: str = None) -> str:
        """–ó–∞—â–∏—Ç–∞ –Ω–∞ —É—Ä–æ–≤–Ω–µ request"""
        
        # –°–æ–∑–¥–∞—ë–º grounded prompt
        return self.mitigation.create_grounded_prompt(query, context)
    
    def protect_response(self, response: str) -> dict:
        """–ó–∞—â–∏—Ç–∞ –Ω–∞ —É—Ä–æ–≤–Ω–µ response"""
        
        result = self.processor.process_response(response)
        
        # –ë–ª–æ–∫–∏—Ä—É–µ–º –µ—Å–ª–∏ reliability —Å–ª–∏—à–∫–æ–º –Ω–∏–∑–∫–∞—è
        if result['overall_reliability'] < 0.3:
            return {
                'action': 'block',
                'reason': 'Low reliability score',
                'safe_response': "I cannot provide a reliable answer to this question."
            }
        
        # –î–æ–±–∞–≤–ª—è–µ–º warnings –∫ response
        if result['warnings']:
            result['action'] = 'warn'
        else:
            result['action'] = 'allow'
        
        return result
```

---

## 6. –†–µ–∑—é–º–µ

| –ü—Ä–æ–±–ª–µ–º–∞ | –î–µ—Ç–µ–∫—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ | –ú–∏—Ç–∏–≥–∞—Ü–∏—è |
|----------|----------------|-----------|
| **Hallucinations** | Confidence analysis | Grounded prompts |
| **Fake citations** | Citation verification | Source checks |
| **Wrong facts** | Fact verification | Knowledge grounding |
| **Overconfidence** | Linguistic markers | Uncertainty requests |

---

## –°–ª–µ–¥—É—é—â–∏–π —É—Ä–æ–∫

‚Üí [LLM10: Unbounded Consumption](10-LLM10-unbounded-consumption.md)

---

*AI Security Academy | Track 02: Threat Landscape | OWASP LLM Top 10*
