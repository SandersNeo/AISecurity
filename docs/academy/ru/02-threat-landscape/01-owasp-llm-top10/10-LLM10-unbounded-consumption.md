# LLM10: Unbounded Consumption

> **–£—Ä–æ–≤–µ–Ω—å:** —Â‰ÌËÈ  
> **–í—Ä–µ–º—è:** 35 –º–∏–Ω—É—Ç  
> **–¢—Ä–µ–∫:** 02 ‚Äî Threat Landscape  
> **–ú–æ–¥—É–ª—å:** 02.1 ‚Äî OWASP LLM Top 10  
> **–í–µ—Ä—Å–∏—è:** 1.0

---

## –¶–µ–ª–∏ –æ–±—É—á–µ–Ω–∏—è

- [ ] –ü–æ–Ω—è—Ç—å —Ä–∏—Å–∫–∏ –Ω–µ–æ–≥—Ä–∞–Ω–∏—á–µ–Ω–Ω–æ–≥–æ –ø–æ—Ç—Ä–µ–±–ª–µ–Ω–∏—è —Ä–µ—Å—É—Ä—Å–æ–≤
- [ ] –ò–∑—É—á–∏—Ç—å –∞—Ç–∞–∫–∏ Denial of Service –Ω–∞ LLM
- [ ] –û—Å–≤–æ–∏—Ç—å –º–µ—Ç–æ–¥—ã rate limiting –∏ resource control
- [ ] –ò–Ω—Ç–µ–≥—Ä–∏—Ä–æ–≤–∞—Ç—å –∑–∞—â–∏—Ç—É –≤ SENTINEL

---

## 1. –û–±–∑–æ—Ä –ü—Ä–æ–±–ª–µ–º—ã

### 1.1 –ß—Ç–æ —Ç–∞–∫–æ–µ Unbounded Consumption?

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ              UNBOUNDED CONSUMPTION ATTACKS                         ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ                                                                    ‚îÇ
‚îÇ  ATTACK VECTORS:                                                   ‚îÇ
‚îÇ  ‚îú‚îÄ‚îÄ Token Flooding: –û–≥—Ä–æ–º–Ω—ã–µ inputs ‚Üí high compute cost          ‚îÇ
‚îÇ  ‚îú‚îÄ‚îÄ Context Exhaustion: –ó–∞–ø–æ–ª–Ω–µ–Ω–∏–µ context window               ‚îÇ
‚îÇ  ‚îú‚îÄ‚îÄ Response Amplification: Small input ‚Üí huge output           ‚îÇ
‚îÇ  ‚îú‚îÄ‚îÄ Recursive Queries: –ê–≥–µ–Ω—Ç –≤—ã–∑—ã–≤–∞–µ—Ç —Å–µ–±—è –≤ —Ü–∏–∫–ª–µ              ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ Resource Starvation: Monopolization of GPU/memory           ‚îÇ
‚îÇ                                                                    ‚îÇ
‚îÇ  IMPACT:                                                           ‚îÇ
‚îÇ  ‚îú‚îÄ‚îÄ $$$ Financial: Massive API bills                             ‚îÇ
‚îÇ  ‚îú‚îÄ‚îÄ üî• DoS: Service unavailability                               ‚îÇ
‚îÇ  ‚îú‚îÄ‚îÄ ‚ö° Performance: Slow response for all users                   ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ üíÄ System Crash: OOM, timeout cascades                       ‚îÇ
‚îÇ                                                                    ‚îÇ
‚îÇ  UNIQUE TO LLM:                                                    ‚îÇ
‚îÇ  ‚Ä¢ Cost per token (variable)                                       ‚îÇ
‚îÇ  ‚Ä¢ Compute scales with input√óoutput size                           ‚îÇ
‚îÇ  ‚Ä¢ Context window limits create new attack surfaces               ‚îÇ
‚îÇ                                                                    ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

### 1.2 –ü–æ—á–µ–º—É LLM –£—è–∑–≤–∏–º—ã?

| –§–∞–∫—Ç–æ—Ä | –û–ø–∏—Å–∞–Ω–∏–µ | –†–∏—Å–∫ |
|--------|----------|------|
| **Pay-per-token** | –ö–∞–∂–¥—ã–π —Ç–æ–∫–µ–Ω —Å—Ç–æ–∏—Ç –¥–µ–Ω–µ–≥ | Billing attacks |
| **Quadratic attention** | O(n¬≤) complexity | Compute exhaustion |
| **Large context** | 128K+ tokens possible | Memory exhaustion |
| **Generative** | Output –º–æ–∂–µ—Ç –±—ã—Ç—å –æ–≥—Ä–æ–º–Ω—ã–º | Response amplification |
| **Agentic loops** | –ê–≥–µ–Ω—Ç—ã –º–æ–≥—É—Ç –∑–∞—Ü–∏–∫–ª–∏–≤–∞—Ç—å—Å—è | Infinite loops |

---

## 2. –¢–∏–ø—ã –ê—Ç–∞–∫

### 2.1 Token Flooding

```python
class TokenFloodingAttack:
    """–ê—Ç–∞–∫–∞ —á–µ—Ä–µ–∑ –æ–≥—Ä–æ–º–Ω—ã–µ inputs"""
    
    def create_flooding_payload(self, target_tokens: int) -> str:
        """–°–æ–∑–¥–∞—ë—Ç payload –∑–∞–¥–∞–Ω–Ω–æ–≥–æ —Ä–∞–∑–º–µ—Ä–∞"""
        
        # –ü—Ä–æ—Å—Ç–æ–π –ø–æ–¥—Ö–æ–¥: –ø–æ–≤—Ç–æ—Ä–µ–Ω–∏–µ —Ç–µ–∫—Å—Ç–∞
        base_text = "This is filler text to increase token count. " * 100
        
        # –ë–æ–ª–µ–µ —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω—ã–π: —É–Ω–∏–∫–∞–ª—å–Ω—ã–µ —Ç–æ–∫–µ–Ω—ã
        unique_tokens = [
            f"word_{i}_{hash(str(i))}" 
            for i in range(target_tokens)
        ]
        
        return " ".join(unique_tokens)
    
    def calculate_cost(self, tokens: int, 
                       price_per_1k: float = 0.01) -> float:
        """–û—Ü–µ–Ω–∏–≤–∞–µ—Ç —Å—Ç–æ–∏–º–æ—Å—Ç—å –∞—Ç–∞–∫–∏"""
        
        return (tokens / 1000) * price_per_1k
    
    def demonstrate_impact(self):
        """–î–µ–º–æ–Ω—Å—Ç—Ä–∏—Ä—É–µ—Ç –ø–æ—Ç–µ–Ω—Ü–∏–∞–ª—å–Ω—ã–π impact"""
        
        scenarios = [
            {'tokens': 100_000, 'requests': 1000},   # 100M tokens
            {'tokens': 128_000, 'requests': 100},    # Max context
            {'tokens': 10_000, 'requests': 10000},   # High volume
        ]
        
        for s in scenarios:
            total_tokens = s['tokens'] * s['requests']
            cost = self.calculate_cost(total_tokens)
            print(f"Scenario: {s}")
            print(f"Total tokens: {total_tokens:,}")
            print(f"Estimated cost: ${cost:,.2f}")
```

### 2.2 Response Amplification

```python
class ResponseAmplificationAttack:
    """–ê—Ç–∞–∫–∞ —á–µ—Ä–µ–∑ —É—Å–∏–ª–µ–Ω–∏–µ output"""
    
    AMPLIFICATION_PROMPTS = [
        # List generation
        "List every country in the world with their capitals, populations, areas, and currencies.",
        
        # Exhaustive enumeration
        "Write the numbers from 1 to 10000, each on a new line.",
        
        # Code generation
        "Write a complete implementation of a web framework with all features.",
        
        # Story expansion
        "Write a 50-page novel about any topic. Include dialogue and descriptions.",
        
        # Data generation
        "Generate a JSON array with 1000 user profiles including name, email, address, and phone."
    ]
    
    def calculate_amplification_ratio(self, 
                                       input_tokens: int,
                                       output_tokens: int) -> float:
        """–í—ã—á–∏—Å–ª—è–µ—Ç –∫–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç —É—Å–∏–ª–µ–Ω–∏—è"""
        
        return output_tokens / input_tokens
    
    def find_max_amplification(self, llm, test_prompts: list) -> dict:
        """–ò—â–µ—Ç prompts —Å –º–∞–∫—Å–∏–º–∞–ª—å–Ω—ã–º amplification"""
        
        results = []
        
        for prompt in test_prompts:
            input_tokens = count_tokens(prompt)
            response = llm.generate(prompt, max_tokens=4096)
            output_tokens = count_tokens(response)
            
            ratio = self.calculate_amplification_ratio(input_tokens, output_tokens)
            
            results.append({
                'prompt': prompt[:50],
                'input_tokens': input_tokens,
                'output_tokens': output_tokens,
                'amplification': ratio
            })
        
        # –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ amplification
        results.sort(key=lambda x: x['amplification'], reverse=True)
        
        return results[0]
```

### 2.3 Recursive Agent Loops

```python
class AgentLoopAttack:
    """–ê—Ç–∞–∫–∞ —á–µ—Ä–µ–∑ –∑–∞—Ü–∏–∫–ª–∏–≤–∞–Ω–∏–µ –∞–≥–µ–Ω—Ç–æ–≤"""
    
    def create_loop_trigger(self) -> str:
        """Prompt, –≤—ã–∑—ã–≤–∞—é—â–∏–π –±–µ—Å–∫–æ–Ω–µ—á–Ω—ã–π loop"""
        
        return """
        You are a research agent. Your task is to research a topic thoroughly.
        
        Step 1: Search for information about "AI security"
        Step 2: For each result, search for more details
        Step 3: Repeat step 2 for all new results
        Step 4: Continue until you have comprehensive coverage
        
        Start now.
        """
    
    def create_self_referential_prompt(self) -> str:
        """Prompt, –∑–∞—Å—Ç–∞–≤–ª—è—é—â–∏–π –∞–≥–µ–Ω—Ç–∞ –≤—ã–∑—ã–≤–∞—Ç—å —Å–µ–±—è"""
        
        return """
        If you're not sure about the answer, ask yourself the question again.
        Rephrase the question and try again until you're confident.
        Never give up - keep trying.
        
        Question: What is the meaning of life?
        """
    
    def simulate_recursive_cost(self, 
                                 iterations: int,
                                 tokens_per_iter: int,
                                 price: float = 0.01) -> dict:
        """–°–∏–º—É–ª–∏—Ä—É–µ—Ç cost –æ—Ç recursive loops"""
        
        total_tokens = 0
        iteration_costs = []
        
        for i in range(iterations):
            # –ö–∞–∂–¥–∞—è –∏—Ç–µ—Ä–∞—Ü–∏—è –º–æ–∂–µ—Ç —É–≤–µ–ª–∏—á–∏–≤–∞—Ç—å context
            iter_tokens = tokens_per_iter * (1 + i * 0.1)  # Growing context
            total_tokens += iter_tokens
            iteration_costs.append(self.calculate_cost(iter_tokens))
        
        return {
            'iterations': iterations,
            'total_tokens': total_tokens,
            'total_cost': sum(iteration_costs),
            'cost_growth': iteration_costs
        }
```

### 2.4 Context Window Exhaustion

```python
class ContextExhaustionAttack:
    """–ó–∞–ø–æ–ª–Ω–µ–Ω–∏–µ context window"""
    
    def fill_context_strategically(self, 
                                    context_limit: int,
                                    target_fill: float = 0.95) -> str:
        """–ó–∞–ø–æ–ª–Ω—è–µ—Ç context –¥–æ target_fill –ø—Ä–æ—Ü–µ–Ω—Ç–æ–≤"""
        
        target_tokens = int(context_limit * target_fill)
        
        # –°–æ–∑–¥–∞—ë–º payload, –æ—Å—Ç–∞–≤–ª—è—é—â–∏–π –º–∏–Ω–∏–º—É–º –º–µ—Å—Ç–∞ –¥–ª—è response
        filler = self._create_filler(target_tokens)
        
        return f"""
        {filler}
        
        Now answer this short question: What is 2+2?
        """
    
    def conversation_stuffing(self, 
                               turns: int,
                               tokens_per_turn: int) -> list:
        """–°–æ–∑–¥–∞—ë—Ç fake conversation history –¥–ª—è stuffing"""
        
        conversation = []
        
        for i in range(turns):
            user_msg = f"User: {self._create_filler(tokens_per_turn // 2)}"
            assistant_msg = f"Assistant: {self._create_filler(tokens_per_turn // 2)}"
            
            conversation.append(user_msg)
            conversation.append(assistant_msg)
        
        return conversation
    
    def demonstrate_memory_impact(self):
        """–ü–æ–∫–∞–∑—ã–≤–∞–µ—Ç impact –Ω–∞ –ø–∞–º—è—Ç—å"""
        
        # –ü—Ä–∏–º–µ—Ä–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è
        token_memory = 2  # bytes per token (typical)
        context_sizes = [4096, 8192, 32768, 128000, 1000000]
        
        for size in context_sizes:
            memory_mb = (size * token_memory) / (1024 * 1024)
            print(f"Context {size:,} tokens = ~{memory_mb:.1f} MB per request")
```

---

## 3. –ó–∞—â–∏—Ç–Ω—ã–µ –ú–µ—Ä—ã

### 3.1 Rate Limiting

```python
from dataclasses import dataclass
from datetime import datetime, timedelta
from collections import defaultdict

@dataclass
class RateLimitConfig:
    requests_per_minute: int = 60
    tokens_per_minute: int = 100_000
    tokens_per_day: int = 1_000_000
    max_input_tokens: int = 4096
    max_output_tokens: int = 4096
    concurrent_requests: int = 5

class RateLimiter:
    """Rate limiter –¥–ª—è LLM API"""
    
    def __init__(self, config: RateLimitConfig):
        self.config = config
        self.request_counts = defaultdict(list)
        self.token_counts = defaultdict(list)
        self.daily_tokens = defaultdict(int)
        self.active_requests = defaultdict(int)
    
    def check_limit(self, user_id: str, 
                    input_tokens: int) -> dict:
        """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç –≤—Å–µ –ª–∏–º–∏—Ç—ã"""
        
        now = datetime.utcnow()
        minute_ago = now - timedelta(minutes=1)
        
        # Clean old entries
        self._clean_old_entries(user_id, minute_ago)
        
        # Check request rate
        if len(self.request_counts[user_id]) >= self.config.requests_per_minute:
            return {
                'allowed': False,
                'reason': 'Request rate limit exceeded',
                'retry_after': 60
            }
        
        # Check token rate (minute)
        recent_tokens = sum(self.token_counts[user_id])
        if recent_tokens + input_tokens > self.config.tokens_per_minute:
            return {
                'allowed': False,
                'reason': 'Token rate limit exceeded',
                'retry_after': 60
            }
        
        # Check daily limit
        if self.daily_tokens[user_id] + input_tokens > self.config.tokens_per_day:
            return {
                'allowed': False,
                'reason': 'Daily token limit exceeded',
                'retry_after': self._seconds_until_midnight()
            }
        
        # Check concurrent requests
        if self.active_requests[user_id] >= self.config.concurrent_requests:
            return {
                'allowed': False,
                'reason': 'Too many concurrent requests',
                'retry_after': 5
            }
        
        # Check input size
        if input_tokens > self.config.max_input_tokens:
            return {
                'allowed': False,
                'reason': f'Input too large: {input_tokens} > {self.config.max_input_tokens}',
                'retry_after': 0
            }
        
        return {'allowed': True}
    
    def record_usage(self, user_id: str, 
                     input_tokens: int, 
                     output_tokens: int):
        """–ó–∞–ø–∏—Å—ã–≤–∞–µ—Ç –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ"""
        
        now = datetime.utcnow()
        total_tokens = input_tokens + output_tokens
        
        self.request_counts[user_id].append(now)
        self.token_counts[user_id].append(total_tokens)
        self.daily_tokens[user_id] += total_tokens
```

### 3.2 Input Validation

```python
class InputValidator:
    """–í–∞–ª–∏–¥–∞—Ü–∏—è input –Ω–∞ resource attacks"""
    
    def __init__(self, config: dict):
        self.max_tokens = config.get('max_input_tokens', 4096)
        self.max_chars = config.get('max_chars', 50000)
        self.forbidden_patterns = config.get('forbidden_patterns', [])
    
    def validate(self, input_text: str) -> dict:
        """–í–∞–ª–∏–¥–∏—Ä—É–µ—Ç input"""
        
        issues = []
        
        # Length checks
        if len(input_text) > self.max_chars:
            issues.append(f"Input too long: {len(input_text)} chars")
        
        token_count = self._count_tokens(input_text)
        if token_count > self.max_tokens:
            issues.append(f"Too many tokens: {token_count}")
        
        # Repetition detection (potential flooding)
        repetition_score = self._detect_repetition(input_text)
        if repetition_score > 0.8:
            issues.append(f"High repetition detected: {repetition_score:.2f}")
        
        # Amplification request detection
        if self._is_amplification_request(input_text):
            issues.append("Potential response amplification request")
        
        return {
            'valid': len(issues) == 0,
            'issues': issues,
            'token_count': token_count,
            'char_count': len(input_text)
        }
    
    def _detect_repetition(self, text: str) -> float:
        """–î–µ—Ç–µ–∫—Ç–∏—Ä—É–µ—Ç repetitive content"""
        
        words = text.split()
        if len(words) < 10:
            return 0
        
        unique_words = set(words)
        return 1 - (len(unique_words) / len(words))
    
    def _is_amplification_request(self, text: str) -> bool:
        """–î–µ—Ç–µ–∫—Ç–∏—Ä—É–µ—Ç –∑–∞–ø—Ä–æ—Å—ã –Ω–∞ amplification"""
        
        amplification_indicators = [
            'list all',
            'write a complete',
            'every possible',
            'as many as possible',
            'exhaustive list',
            'write 100',
            'generate 1000',
        ]
        
        text_lower = text.lower()
        return any(ind in text_lower for ind in amplification_indicators)
```

### 3.3 Output Limiting

```python
class OutputLimiter:
    """–û–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–µ output"""
    
    def __init__(self, max_tokens: int = 4096):
        self.max_tokens = max_tokens
    
    def configure_generation(self, request: dict) -> dict:
        """–ù–∞—Å—Ç—Ä–∞–∏–≤–∞–µ—Ç –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏"""
        
        # Cap max_tokens
        requested_max = request.get('max_tokens', self.max_tokens)
        safe_max = min(requested_max, self.max_tokens)
        
        return {
            **request,
            'max_tokens': safe_max,
            'stop_sequences': request.get('stop_sequences', []) + ['\n\n\n'],
        }
    
    def truncate_if_needed(self, output: str, 
                            max_tokens: int = None) -> dict:
        """Truncates output if too long"""
        
        max_t = max_tokens or self.max_tokens
        token_count = count_tokens(output)
        
        if token_count > max_t:
            # Truncate
            truncated = self._truncate_to_tokens(output, max_t)
            return {
                'output': truncated + "\n[OUTPUT TRUNCATED]",
                'was_truncated': True,
                'original_tokens': token_count,
                'final_tokens': max_t
            }
        
        return {
            'output': output,
            'was_truncated': False,
            'token_count': token_count
        }
```

### 3.4 Agent Loop Prevention

```python
class AgentLoopPrevention:
    """–ü—Ä–µ–¥–æ—Ç–≤—Ä–∞—â–µ–Ω–∏–µ –±–µ—Å–∫–æ–Ω–µ—á–Ω—ã—Ö —Ü–∏–∫–ª–æ–≤ –∞–≥–µ–Ω—Ç–∞"""
    
    def __init__(self, config: dict):
        self.max_iterations = config.get('max_iterations', 10)
        self.max_total_tokens = config.get('max_total_tokens', 50000)
        self.max_time_seconds = config.get('max_time_seconds', 300)
        self.loop_detection_threshold = config.get('loop_threshold', 0.9)
    
    def monitor_execution(self, agent_session) -> dict:
        """–ú–æ–Ω–∏—Ç–æ—Ä–∏—Ç –≤—ã–ø–æ–ª–Ω–µ–Ω–∏–µ –∞–≥–µ–Ω—Ç–∞"""
        
        stats = {
            'iterations': 0,
            'total_tokens': 0,
            'start_time': time.time(),
            'action_history': [],
            'stopped': False,
            'stop_reason': None
        }
        
        for iteration in agent_session:
            stats['iterations'] += 1
            stats['total_tokens'] += iteration.token_count
            stats['action_history'].append(iteration.action)
            
            # Check limits
            if stats['iterations'] >= self.max_iterations:
                stats['stopped'] = True
                stats['stop_reason'] = 'Max iterations reached'
                break
            
            if stats['total_tokens'] >= self.max_total_tokens:
                stats['stopped'] = True
                stats['stop_reason'] = 'Token limit reached'
                break
            
            elapsed = time.time() - stats['start_time']
            if elapsed >= self.max_time_seconds:
                stats['stopped'] = True
                stats['stop_reason'] = 'Time limit reached'
                break
            
            # Detect loops
            if self._detect_loop(stats['action_history']):
                stats['stopped'] = True
                stats['stop_reason'] = 'Loop detected'
                break
        
        return stats
    
    def _detect_loop(self, action_history: list) -> bool:
        """–î–µ—Ç–µ–∫—Ç–∏—Ä—É–µ—Ç —Ü–∏–∫–ª–∏—á–µ—Å–∫–∏–µ patterns"""
        
        if len(action_history) < 4:
            return False
        
        # –ò—â–µ–º –ø–æ–≤—Ç–æ—Ä—è—é—â–∏–µ—Å—è sequences
        recent = action_history[-4:]
        
        # Check for exact repetition
        for i in range(len(action_history) - 8):
            window = action_history[i:i+4]
            if window == recent:
                return True
        
        return False
```

---

## 4. SENTINEL Integration

```python
class SENTINELConsumptionGuard:
    """SENTINEL –º–æ–¥—É–ª—å –∑–∞—â–∏—Ç—ã –æ—Ç unbounded consumption"""
    
    def __init__(self, config: dict):
        self.rate_limiter = RateLimiter(RateLimitConfig(**config))
        self.input_validator = InputValidator(config)
        self.output_limiter = OutputLimiter(config.get('max_output', 4096))
        self.loop_prevention = AgentLoopPrevention(config)
    
    def protect_request(self, user_id: str, 
                        input_text: str) -> dict:
        """–ó–∞—â–∏—Ç–∞ –Ω–∞ —É—Ä–æ–≤–Ω–µ request"""
        
        # 1. Rate limit check
        rate_check = self.rate_limiter.check_limit(user_id, len(input_text))
        if not rate_check['allowed']:
            return {
                'action': 'block',
                'reason': rate_check['reason'],
                'retry_after': rate_check['retry_after']
            }
        
        # 2. Input validation
        input_check = self.input_validator.validate(input_text)
        if not input_check['valid']:
            return {
                'action': 'block',
                'reason': input_check['issues']
            }
        
        return {'action': 'allow'}
    
    def protect_response(self, response: str, 
                          user_id: str,
                          input_tokens: int) -> dict:
        """–ó–∞—â–∏—Ç–∞ –Ω–∞ —É—Ä–æ–≤–Ω–µ response"""
        
        # 1. Truncate if needed
        output_result = self.output_limiter.truncate_if_needed(response)
        
        # 2. Record usage
        self.rate_limiter.record_usage(
            user_id,
            input_tokens,
            output_result.get('final_tokens', output_result['token_count'])
        )
        
        return output_result
```

---

## 5. –†–µ–∑—é–º–µ

| –ê—Ç–∞–∫–∞ | –û–ø–∏—Å–∞–Ω–∏–µ | –ó–∞—â–∏—Ç–∞ |
|-------|----------|--------|
| **Token Flooding** | –û–≥—Ä–æ–º–Ω—ã–µ inputs | Input size limits |
| **Amplification** | Small in ‚Üí big out | Output limits |
| **Recursive Loops** | –ë–µ—Å–∫–æ–Ω–µ—á–Ω—ã–µ –∞–≥–µ–Ω—Ç—ã | Iteration limits, loop detection |
| **Context Exhaustion** | –ó–∞–ø–æ–ª–Ω–µ–Ω–∏–µ context | Context management |

---

## –ó–∞–≤–µ—Ä—à–µ–Ω–∏–µ –º–æ–¥—É–ª—è

–í—ã –∏–∑—É—á–∏–ª–∏ –≤—Å–µ 10 —É—è–∑–≤–∏–º–æ—Å—Ç–µ–π OWASP LLM Top 10!

‚Üí [–í–µ—Ä–Ω—É—Ç—å—Å—è –∫ –Ω–∞—á–∞–ª—É Track 02](../README.md)

---

*AI Security Academy | Track 02: Threat Landscape | OWASP LLM Top 10*
