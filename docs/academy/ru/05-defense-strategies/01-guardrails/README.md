# Guardrails (Primary)

> **Submodule 05.1b: Core Guardrail Implementation**

---

## Обзор

Guardrails are active controls that enforce security policies at runtime. This submodule covers implementation patterns for input, output, and system-level guardrails with practical code examples.

---

## Guardrail Types

| Type | Position | Purpose | Latency Impact |
|------|----------|---------|----------------|
| **Input** | Before LLM | Block malicious requests | Low |
| **Output** | After LLM | Block harmful responses | Medium |
| **System** | Always | Enforce invariants | Minimal |
| **Action** | Tool-level | Control agent actions | Low |

---

## Lessons

### 01. Input Guardrails
**Время:** 40 minutes | **Сложность:** Средний

Filtering incoming requests:
- Content policy enforcement patterns
- Injection detection integration
- Topic restrictions implementation
- Rate limiting strategies

### 02. Output Guardrails
**Время:** 40 minutes | **Сложность:** Средний

Filtering model responses:
- Harmful content blocking
- PII and credential redaction
- Policy compliance verification
- Response modification patterns

---

## Implementation Patterns

### Basic Guardrail
```python
from sentinel import Guard

guard = Guard(
    input_policy="strict",
    output_redaction=["pii", "credentials"],
    system_limits={"max_tokens": 4096, "timeout": 30}
)

@guard.protect
async def process_request(user_input: str) -> str:
    return await llm.generate(user_input)
```

---

## Guardrail Architecture

```
User Input
    в”‚
    в–ј
в”Њв”Ђв”Ђв”Ђв”Ђв”Ђв”Ђв”Ђв”Ђв”Ђв”Ђв”Ђв”Ђв”Ђв”Ђв”Ђв”Ђв”Ђв”Ђв”Ђв”Ђв”ђ
в”‚  INPUT GUARDRAILS  в”‚ в†ђ Block/modify before LLM
в”‚  в”њв”Ђв”Ђ Policy check  в”‚
в”‚  в”њв”Ђв”Ђ Injection scanв”‚
в”‚  в””в”Ђв”Ђ Rate limit    в”‚
в””в”Ђв”Ђв”Ђв”Ђв”Ђв”Ђв”Ђв”Ђв”Ђв”Ђв”Ђв”Ђв”Ђв”Ђв”Ђв”Ђв”Ђв”Ђв”Ђв”Ђв”
    в”‚ (if allowed)
    в–ј
в”Њв”Ђв”Ђв”Ђв”Ђв”Ђв”Ђв”Ђв”Ђв”Ђв”Ђв”Ђв”Ђв”Ђв”Ђв”Ђв”Ђв”Ђв”Ђв”Ђв”Ђв”ђ
в”‚       LLM          в”‚
в””в”Ђв”Ђв”Ђв”Ђв”Ђв”Ђв”Ђв”Ђв”Ђв”Ђв”Ђв”Ђв”Ђв”Ђв”Ђв”Ђв”Ђв”Ђв”Ђв”Ђв”
    в”‚
    в–ј
в”Њв”Ђв”Ђв”Ђв”Ђв”Ђв”Ђв”Ђв”Ђв”Ђв”Ђв”Ђв”Ђв”Ђв”Ђв”Ђв”Ђв”Ђв”Ђв”Ђв”Ђв”ђ
в”‚ OUTPUT GUARDRAILS  в”‚ в†ђ Block/modify after LLM
в”‚  в”њв”Ђв”Ђ Content check в”‚
в”‚  в”њв”Ђв”Ђ PII redaction в”‚
в”‚  в””в”Ђв”Ђ Policy verify в”‚
в””в”Ђв”Ђв”Ђв”Ђв”Ђв”Ђв”Ђв”Ђв”Ђв”Ђв”Ђв”Ђв”Ђв”Ђв”Ђв”Ђв”Ђв”Ђв”Ђв”Ђв”
    в”‚ (if safe)
    в–ј
User Response
```

---

## Навигация

| Previous | Current | Next |
|----------|---------|------|
| [Detection](../01-detection/) | **Guardrails** | [Response](../02-response/) |

---

*AI Security Academy | Core Guardrails*
