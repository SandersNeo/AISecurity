# –ì–∞–ª–µ—Ä–µ—è –ø—Ä–∏–º–µ—Ä–æ–≤

–ü—Ä–∞–∫—Ç–∏—á–µ—Å–∫–∏–µ, –≥–æ—Ç–æ–≤—ã–µ –∫ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—é –ø—Ä–∏–º–µ—Ä—ã –¥–ª—è –∫–∞–∂–¥–æ–≥–æ —Å—Ü–µ–Ω–∞—Ä–∏—è RLM-Toolkit.

## –ë—ã—Å—Ç—Ä–∞—è –Ω–∞–≤–∏–≥–∞—Ü–∏—è

| –ö–∞—Ç–µ–≥–æ—Ä–∏—è | –ü—Ä–∏–º–µ—Ä—ã |
|-----------|---------|
| [–ë–∞–∑–æ–≤—ã–µ](#–±–∞–∑–æ–≤—ã–µ) | Hello World, –ß–∞—Ç, Streaming |
| [RAG](#rag) | PDF Q&A, Web Scraper, –ì–∏–±—Ä–∏–¥–Ω—ã–π –ø–æ–∏—Å–∫ |
| [–ê–≥–µ–Ω—Ç—ã](#–∞–≥–µ–Ω—Ç—ã) | Research Agent, –ö–æ–¥-–∞—Å—Å–∏—Å—Ç–µ–Ω—Ç, –ê–Ω–∞–ª–∏—Ç–∏–∫ |
| [–ü–∞–º—è—Ç—å](#–ø–∞–º—è—Ç—å) | –ü–µ—Ä—Å–∏—Å—Ç–µ–Ω—Ç–Ω—ã–π —á–∞—Ç, H-MEM, –ú–µ–Ω–µ–¥–∂–µ—Ä —Å–µ—Å—Å–∏–π |
| [–ü—Ä–æ–¥–≤–∏–Ω—É—Ç—ã–µ](#–ø—Ä–æ–¥–≤–∏–Ω—É—Ç—ã–µ) | InfiniRetri, Self-Evolving, Multi-Agent |
| [–ü—Ä–æ–¥–∞–∫—à–Ω](#–ø—Ä–æ–¥–∞–∫—à–Ω) | FastAPI, Docker, Kubernetes |
| [–ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏–∏](#–∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏–∏) | Slack Bot, Discord, Telegram |

---

## –ë–∞–∑–æ–≤—ã–µ

### Hello World

```python
from rlm_toolkit import RLM

rlm = RLM.from_openai("gpt-4o")
print(rlm.run("–ü—Ä–∏–≤–µ—Ç, –º–∏—Ä!"))
```

### –ü—Ä–æ—Å—Ç–æ–π —á–∞—Ç

```python
from rlm_toolkit import RLM
from rlm_toolkit.memory import BufferMemory

rlm = RLM.from_openai("gpt-4o", memory=BufferMemory())

while True:
    user_input = input("–í—ã: ")
    if user_input.lower() == "–≤—ã—Ö–æ–¥":
        break
    response = rlm.run(user_input)
    print(f"AI: {response}")
```

### Streaming –æ—Ç–≤–µ—Ç

```python
from rlm_toolkit import RLM

rlm = RLM.from_openai("gpt-4o")

for chunk in rlm.stream("–†–∞—Å—Å–∫–∞–∂–∏ –∏—Å—Ç–æ—Ä–∏—é –æ —Ä–æ–±–æ—Ç–µ"):
    print(chunk, end="", flush=True)
```

### JSON –≤—ã–≤–æ–¥

```python
from rlm_toolkit import RLM, RLMConfig

config = RLMConfig(json_mode=True)
rlm = RLM.from_openai("gpt-4o", config=config)

result = rlm.run("""
–ò–∑–≤–ª–µ–∫–∏ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ —á–µ–ª–æ–≤–µ–∫–µ:
"–ò–≤–∞–Ω –ü–µ—Ç—Ä–æ–≤, 35 –ª–µ—Ç, —Ä–∞–±–æ—Ç–∞–µ—Ç –≤ –Ø–Ω–¥–µ–∫—Å–µ –∫–∞–∫ Senior Engineer"

–í–µ—Ä–Ω–∏ –∫–∞–∫: {"name": str, "age": int, "company": str, "role": str}
""")
print(result)
```

### –°—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –≤—ã–≤–æ–¥ (Pydantic)

```python
from pydantic import BaseModel
from rlm_toolkit import RLM

class Product(BaseModel):
    name: str
    price: float
    in_stock: bool

rlm = RLM.from_openai("gpt-4o")
product = rlm.run_structured(
    "iPhone 15 Pro, 99990‚ÇΩ, –≤ –Ω–∞–ª–∏—á–∏–∏",
    output_schema=Product
)
print(f"{product.name}: {product.price}‚ÇΩ")
```

### –ù–µ—Å–∫–æ–ª—å–∫–æ –ø—Ä–æ–≤–∞–π–¥–µ—Ä–æ–≤

```python
from rlm_toolkit import RLM

# OpenAI
gpt = RLM.from_openai("gpt-4o")

# Anthropic
claude = RLM.from_anthropic("claude-3-sonnet")

# Google
gemini = RLM.from_google("gemini-pro")

# –õ–æ–∫–∞–ª—å–Ω—ã–π (Ollama)
llama = RLM.from_ollama("llama3")

# –°—Ä–∞–≤–Ω–µ–Ω–∏–µ –≤—ã–≤–æ–¥–æ–≤
query = "–û–±—ä—è—Å–Ω–∏ –∫–≤–∞–Ω—Ç–æ–≤—ã–µ –≤—ã—á–∏—Å–ª–µ–Ω–∏—è –≤ –æ–¥–Ω–æ–º –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–∏"
print(f"GPT: {gpt.run(query)}")
print(f"Claude: {claude.run(query)}")
print(f"Gemini: {gemini.run(query)}")
print(f"Llama: {llama.run(query)}")
```

### –ê–Ω–∞–ª–∏–∑ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π (Vision)

```python
from rlm_toolkit import RLM

rlm = RLM.from_openai("gpt-4o")

result = rlm.run(
    "–ß—Ç–æ –Ω–∞ —ç—Ç–æ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–∏? –û–ø–∏—à–∏ –ø–æ–¥—Ä–æ–±–Ω–æ.",
    images=["./photo.jpg"]
)
print(result)
```

### –ü–µ—Ä–µ–≤–æ–¥

```python
from rlm_toolkit import RLM

rlm = RLM.from_openai("gpt-4o")
rlm.set_system_prompt("–¢—ã –ø–µ—Ä–µ–≤–æ–¥—á–∏–∫. –ü–µ—Ä–µ–≤–æ–¥–∏ –Ω–∞ –∑–∞–ø—Ä–æ—à–µ–Ω–Ω—ã–π —è–∑—ã–∫.")

text = "–ó–¥—Ä–∞–≤—Å—Ç–≤—É–π—Ç–µ, –∫–∞–∫ –≤–∞—à–∏ –¥–µ–ª–∞?"
print(rlm.run(f"–ü–µ—Ä–µ–≤–µ–¥–∏ –Ω–∞ –∞–Ω–≥–ª–∏–π—Å–∫–∏–π: {text}"))
print(rlm.run(f"–ü–µ—Ä–µ–≤–µ–¥–∏ –Ω–∞ —è–ø–æ–Ω—Å–∫–∏–π: {text}"))
print(rlm.run(f"–ü–µ—Ä–µ–≤–µ–¥–∏ –Ω–∞ –∏—Å–ø–∞–Ω—Å–∫–∏–π: {text}"))
```

### –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –∫–æ–¥–∞

```python
from rlm_toolkit import RLM

rlm = RLM.from_openai("gpt-4o")
rlm.set_system_prompt("""
–¢—ã —ç–∫—Å–ø–µ—Ä—Ç Python. –ì–µ–Ω–µ—Ä–∏—Ä—É–π —á–∏—Å—Ç—ã–π, –¥–æ–∫—É–º–µ–Ω—Ç–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –∫–æ–¥.
–í–∫–ª—é—á–∞–π type hints –∏ docstrings.
""")

code = rlm.run("–ù–∞–ø–∏—à–∏ —Ñ—É–Ω–∫—Ü–∏—é –¥–ª—è –ø–æ–∏—Å–∫–∞ –≤—Å–µ—Ö –ø—Ä–æ—Å—Ç—ã—Ö —á–∏—Å–µ–ª –¥–æ n")
print(code)
```

### –°—É–º–º–∞—Ä–∏–∑–∞—Ü–∏—è

```python
from rlm_toolkit import RLM
from rlm_toolkit.loaders import WebPageLoader

rlm = RLM.from_openai("gpt-4o")

# –ó–∞–≥—Ä—É–∑–∫–∞ —Å—Ç–∞—Ç—å–∏
docs = WebPageLoader("https://example.com/article").load()
text = docs[0].page_content

# –°—É–º–º–∞—Ä–∏–∑–∞—Ü–∏—è
summary = rlm.run(f"""
–°—É–º–º–∏—Ä—É–π —ç—Ç—É —Å—Ç–∞—Ç—å—é –≤ 3 –ø—É–Ω–∫—Ç–∞—Ö:

{text}
""")
print(summary)
```

---

## RAG

### PDF –≤–æ–ø—Ä–æ—Å-–æ—Ç–≤–µ—Ç

```python
from rlm_toolkit import RLM
from rlm_toolkit.loaders import PDFLoader
from rlm_toolkit.splitters import RecursiveTextSplitter
from rlm_toolkit.embeddings import OpenAIEmbeddings
from rlm_toolkit.vectorstores import ChromaVectorStore
from rlm_toolkit.retrievers import VectorStoreRetriever

# –ó–∞–≥—Ä—É–∑–∫–∞ PDF
docs = PDFLoader("company_report.pdf").load()

# –†–∞–∑–±–∏–µ–Ω–∏–µ –Ω–∞ —á–∞–Ω–∫–∏
splitter = RecursiveTextSplitter(chunk_size=1000, chunk_overlap=200)
chunks = splitter.split_documents(docs)

# –°–æ–∑–¥–∞–Ω–∏–µ –≤–µ–∫—Ç–æ—Ä–Ω–æ–≥–æ —Ö—Ä–∞–Ω–∏–ª–∏—â–∞
embeddings = OpenAIEmbeddings("text-embedding-3-small")
vectorstore = ChromaVectorStore.from_documents(chunks, embeddings)

# –°–æ–∑–¥–∞–Ω–∏–µ —Ä–µ—Ç—Ä–∏–≤–µ—Ä–∞
retriever = VectorStoreRetriever(vectorstore, search_kwargs={"k": 5})

# –°–æ–∑–¥–∞–Ω–∏–µ RLM —Å —Ä–µ—Ç—Ä–∏–≤–µ—Ä–æ–º
rlm = RLM.from_openai("gpt-4o")
rlm.set_retriever(retriever)
rlm.set_system_prompt("""
–û—Ç–≤–µ—á–∞–π —Ç–æ–ª—å–∫–æ –Ω–∞ –æ—Å–Ω–æ–≤–µ –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª–µ–Ω–Ω–æ–≥–æ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞.
–£–∫–∞–∑—ã–≤–∞–π –∏—Å—Ç–æ—á–Ω–∏–∫–∏. –ï—Å–ª–∏ –Ω–µ —É–≤–µ—Ä–µ–Ω, —Å–∫–∞–∂–∏ "–ù–µ –∑–Ω–∞—é".
""")

# –ó–∞–¥–∞–π –≤–æ–ø—Ä–æ—Å—ã
print(rlm.run("–ö–∞–∫–∞—è –±—ã–ª–∞ –≤—ã—Ä—É—á–∫–∞ –∑–∞ Q3?"))
print(rlm.run("–ö—Ç–æ –∫–ª—é—á–µ–≤—ã–µ —Ä—É–∫–æ–≤–æ–¥–∏—Ç–µ–ª–∏?"))
```

### Multi-Document RAG

```python
from rlm_toolkit.loaders import DirectoryLoader, PDFLoader

# –ó–∞–≥—Ä—É–∑–∫–∞ –≤—Å–µ—Ö PDF –∏–∑ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏
loader = DirectoryLoader(
    path="./documents",
    glob="**/*.pdf",
    loader_cls=PDFLoader,
    show_progress=True
)
docs = loader.load()

print(f"–ó–∞–≥—Ä—É–∂–µ–Ω–æ {len(docs)} –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤")
```

### Web RAG

```python
from rlm_toolkit import RLM
from rlm_toolkit.loaders import WebPageLoader
from rlm_toolkit.splitters import MarkdownSplitter
from rlm_toolkit.embeddings import OpenAIEmbeddings
from rlm_toolkit.vectorstores import ChromaVectorStore

# –ü–∞—Ä—Å–∏–Ω–≥ –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏–∏
urls = [
    "https://docs.example.com/getting-started",
    "https://docs.example.com/api-reference",
    "https://docs.example.com/tutorials"
]

docs = WebPageLoader(urls).load()
chunks = MarkdownSplitter(chunk_size=1000).split_documents(docs)

vectorstore = ChromaVectorStore.from_documents(
    chunks, OpenAIEmbeddings()
)

rlm = RLM.from_openai("gpt-4o")
rlm.set_retriever(vectorstore.as_retriever(k=5))

print(rlm.run("–ö–∞–∫ –∞—É—Ç–µ–Ω—Ç–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞—Ç—å—Å—è –≤ API?"))
```

### –ì–∏–±—Ä–∏–¥–Ω—ã–π –ø–æ–∏—Å–∫ RAG

```python
from rlm_toolkit.retrievers import HybridRetriever

retriever = HybridRetriever(
    vectorstore=vectorstore,
    keyword_weight=0.3,
    semantic_weight=0.7,
    fusion_method="rrf"
)

rlm = RLM.from_openai("gpt-4o")
rlm.set_retriever(retriever)

# –õ—É—á—à–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –¥–ª—è —Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–∏—Ö –∏ –∫–ª—é—á–µ–≤—ã—Ö –∑–∞–ø—Ä–æ—Å–æ–≤
print(rlm.run("–∫–æ–¥ –æ—à–∏–±–∫–∏ 404"))  # –ö–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞
print(rlm.run("–ö–∞–∫ –æ–±—Ä–∞–±–æ—Ç–∞—Ç—å –æ—à–∏–±–∫–∏ –∞—É—Ç–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ü–∏–∏"))  # –°–µ–º–∞–Ω—Ç–∏–∫–∞
```

---

## –ê–≥–µ–Ω—Ç—ã

### –ò—Å—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å—Å–∫–∏–π –∞–≥–µ–Ω—Ç

```python
from rlm_toolkit.agents import ReActAgent
from rlm_toolkit.tools import WebSearchTool, WikipediaTool, ArxivTool

agent = ReActAgent.from_openai(
    "gpt-4o",
    tools=[
        WebSearchTool(provider="ddg"),
        WikipediaTool(),
        ArxivTool()
    ]
)

result = agent.run("""
–ò—Å—Å–ª–µ–¥—É–π –ø–æ—Å–ª–µ–¥–Ω–∏–µ —Ä–∞–∑—Ä–∞–±–æ—Ç–∫–∏ –≤ –∫–≤–∞–Ω—Ç–æ–≤—ã—Ö –≤—ã—á–∏—Å–ª–µ–Ω–∏—è—Ö.
–ù–∞–π–¥–∏ —Å–≤–µ–∂–∏–µ —Å—Ç–∞—Ç—å–∏ –∏ —Å—É–º–º–∏—Ä—É–π –∫–ª—é—á–µ–≤—ã–µ –ø—Ä–æ—Ä—ã–≤—ã.
""")
print(result)
```

### –ö–æ–¥-–∞—Å—Å–∏—Å—Ç–µ–Ω—Ç

```python
from rlm_toolkit.agents import ReActAgent
from rlm_toolkit.tools import PythonREPL, FileReader, FileWriter

agent = ReActAgent.from_openai(
    "gpt-4o",
    tools=[
        PythonREPL(max_execution_time=30),
        FileReader(),
        FileWriter()
    ],
    system_prompt="–¢—ã –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç –ø–æ –ø—Ä–æ–≥—Ä–∞–º–º–∏—Ä–æ–≤–∞–Ω–∏—é –Ω–∞ Python."
)

result = agent.run("""
1. –ü—Ä–æ—á–∏—Ç–∞–π —Ñ–∞–π–ª data.csv
2. –ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π –¥–∞–Ω–Ω—ã–µ —Å pandas
3. –°–æ–∑–¥–∞–π –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—é
4. –°–æ—Ö—Ä–∞–Ω–∏ –≥—Ä–∞—Ñ–∏–∫ –∫–∞–∫ chart.png
""")
```

### –ê–Ω–∞–ª–∏—Ç–∏–∫ –¥–∞–Ω–Ω—ã—Ö

```python
from rlm_toolkit.agents import ReActAgent
from rlm_toolkit.tools import PythonREPL, SQLTool

agent = ReActAgent.from_openai(
    "gpt-4o",
    tools=[
        PythonREPL(),
        SQLTool(connection_string="sqlite:///data.db")
    ]
)

result = agent.run("""
–ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π —Ç–∞–±–ª–∏—Ü—É –ø—Ä–æ–¥–∞–∂:
1. –ü–æ–∫–∞–∂–∏ –æ–±—â—É—é –≤—ã—Ä—É—á–∫—É –ø–æ –º–µ—Å—è—Ü–∞–º
2. –ù–∞–π–¥–∏ —Ç–æ–ø-10 –ø—Ä–æ–¥—É–∫—Ç–æ–≤
3. –ü–æ—Å—á–∏—Ç–∞–π retention –∫–ª–∏–µ–Ω—Ç–æ–≤
""")
```

### –ú–∞—Ç–µ–º–∞—Ç–∏–∫

```python
from rlm_toolkit.agents import ReActAgent
from rlm_toolkit.tools import Tool
import sympy

@Tool(name="solve_equation", description="–†–µ—à–∏—Ç—å —É—Ä–∞–≤–Ω–µ–Ω–∏–µ")
def solve_equation(equation: str) -> str:
    x = sympy.Symbol('x')
    result = sympy.solve(equation, x)
    return str(result)

@Tool(name="differentiate", description="–í–∑—è—Ç—å –ø—Ä–æ–∏–∑–≤–æ–¥–Ω—É—é")
def differentiate(expr: str) -> str:
    x = sympy.Symbol('x')
    result = sympy.diff(expr, x)
    return str(result)

agent = ReActAgent.from_openai("gpt-4o", tools=[solve_equation, differentiate])
print(agent.run("–†–µ—à–∏ x^2 - 5x + 6 = 0"))
print(agent.run("–ù–∞–π–¥–∏ –ø—Ä–æ–∏–∑–≤–æ–¥–Ω—É—é x^3 + 2x^2"))
```

---

## –ü–∞–º—è—Ç—å

### –ü–µ—Ä—Å–∏—Å—Ç–µ–Ω—Ç–Ω—ã–π —á–∞—Ç

```python
from rlm_toolkit import RLM
from rlm_toolkit.memory import HierarchicalMemory

memory = HierarchicalMemory(persist_directory="./chat_history")

rlm = RLM.from_openai("gpt-4o", memory=memory)

# –†–∞–∑–≥–æ–≤–æ—Ä —Å–æ—Ö—Ä–∞–Ω—è–µ—Ç—Å—è –º–µ–∂–¥—É —Å–µ—Å—Å–∏—è–º–∏
rlm.run("–ú–µ–Ω—è –∑–æ–≤—É—Ç –ê–ª–µ–∫—Å–µ–π –∏ —è –∏–∑—É—á–∞—é Python")
# ... –ø–µ—Ä–µ–∑–∞–ø—É—Å–∫ ...
rlm.run("–ö–∞–∫ –º–µ–Ω—è –∑–æ–≤—É—Ç?")  # "–í–∞—Å –∑–æ–≤—É—Ç –ê–ª–µ–∫—Å–µ–π"
```

### –ú–µ–Ω–µ–¥–∂–µ—Ä —Å–µ—Å—Å–∏–π

```python
from rlm_toolkit import RLM
from rlm_toolkit.memory import SessionMemory

sessions = {}

def get_session(user_id: str) -> RLM:
    if user_id not in sessions:
        memory = SessionMemory(session_id=user_id)
        sessions[user_id] = RLM.from_openai("gpt-4o", memory=memory)
    return sessions[user_id]

# –£ –∫–∞–∂–¥–æ–≥–æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è –∏–∑–æ–ª–∏—Ä–æ–≤–∞–Ω–Ω–∞—è –ø–∞–º—è—Ç—å
alice = get_session("alice")
bob = get_session("bob")

alice.run("–Ø –ª—é–±–ª—é –∫–æ—à–µ–∫")
bob.run("–Ø –ª—é–±–ª—é —Å–æ–±–∞–∫")

print(alice.run("–ß—Ç–æ —è –ª—é–±–ª—é?"))  # –∫–æ—à–µ–∫
print(bob.run("–ß—Ç–æ —è –ª—é–±–ª—é?"))    # —Å–æ–±–∞–∫
```

---

## –ü—Ä–æ–¥–≤–∏–Ω—É—Ç—ã–µ

### InfiniRetri (1M+ —Ç–æ–∫–µ–Ω–æ–≤)

```python
from rlm_toolkit import RLM, RLMConfig
from rlm_toolkit.retrieval import InfiniRetriConfig
from rlm_toolkit.loaders import PDFLoader

config = RLMConfig(
    enable_infiniretri=True,
    infiniretri_config=InfiniRetriConfig(
        chunk_size=4000,
        top_k=5
    ),
    infiniretri_threshold=50000
)

rlm = RLM.from_openai("gpt-4o", config=config)

# –ó–∞–≥—Ä—É–∑–∫–∞ –æ–≥—Ä–æ–º–Ω–æ–≥–æ –¥–æ–∫—É–º–µ–Ω—Ç–∞ (1000+ —Å—Ç—Ä–∞–Ω–∏—Ü)
docs = PDFLoader("massive_report.pdf").load()

result = rlm.run_with_docs(
    query="–ù–∞–π–¥–∏ —Ä–∞–∑–¥–µ–ª –æ –≤—ã—Ä—É—á–∫–µ Q3 –∏ –æ–±—ä—è—Å–Ω–∏ —Ä–æ—Å—Ç",
    documents=docs
)
print(result)
```

### Self-Evolving (Challenger-Solver)

```python
from rlm_toolkit.evolve import SelfEvolvingRLM, EvolutionConfig

config = EvolutionConfig(
    strategy="challenger_solver",
    max_iterations=5,
    early_stop_threshold=0.95
)

evolving = SelfEvolvingRLM.from_openai("gpt-4o", config=config)

result = evolving.run("""
–ù–∞–ø–∏—à–∏ Python —Ñ—É–Ω–∫—Ü–∏—é –¥–ª—è —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ–≥–æ –ø–æ–∏—Å–∫–∞
—Å–∞–º–æ–π –¥–ª–∏–Ω–Ω–æ–π –ø–∞–ª–∏–Ω–¥—Ä–æ–º–Ω–æ–π –ø–æ–¥—Å—Ç—Ä–æ–∫–∏.
–í–∫–ª—é—á–∏ edge cases –∏ –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—é.
""")
print(result)
```

### Multi-Agent –∫–æ–ª–ª–∞–±–æ—Ä–∞—Ü–∏—è

```python
from rlm_toolkit.agents.multiagent import MetaMatrix, Agent
from rlm_toolkit import RLM
from rlm_toolkit.tools import WebSearchTool, PythonREPL, FileWriter

researcher = Agent(
    name="researcher",
    description="–ò—â–µ—Ç –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é",
    llm=RLM.from_openai("gpt-4o"),
    tools=[WebSearchTool()]
)

analyst = Agent(
    name="analyst", 
    description="–ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç –¥–∞–Ω–Ω—ã–µ –∫–æ–¥–æ–º",
    llm=RLM.from_openai("gpt-4o"),
    tools=[PythonREPL()]
)

writer = Agent(
    name="writer",
    description="–ü–∏—à–µ—Ç –æ—Ç—á—ë—Ç—ã",
    llm=RLM.from_anthropic("claude-3-sonnet"),
    tools=[FileWriter()]
)

matrix = MetaMatrix(topology="mesh", consensus="raft")
matrix.register(researcher)
matrix.register(analyst)
matrix.register(writer)

result = matrix.run("""
1. –ò—Å—Å–ª–µ–¥—É–π AI —Ç—Ä–µ–Ω–¥—ã 2024
2. –ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π –¥–∞–Ω–Ω—ã–µ –∏ —Å–æ–∑–¥–∞–π –≥—Ä–∞—Ñ–∏–∫–∏
3. –ù–∞–ø–∏—à–∏ comprehensive –æ—Ç—á—ë—Ç
–°–æ—Ö—Ä–∞–Ω–∏ –≤—Å—ë –≤ output/
""")
```

---

## –ü—Ä–æ–¥–∞–∫—à–Ω

### FastAPI –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–µ

```python
from fastapi import FastAPI
from pydantic import BaseModel
from rlm_toolkit import RLM
from rlm_toolkit.memory import SessionMemory
import uuid

app = FastAPI(title="RLM Chat API")
sessions = {}

class ChatRequest(BaseModel):
    session_id: str | None = None
    message: str

class ChatResponse(BaseModel):
    session_id: str
    response: str

def get_rlm(session_id: str) -> RLM:
    if session_id not in sessions:
        memory = SessionMemory(session_id=session_id)
        sessions[session_id] = RLM.from_openai("gpt-4o", memory=memory)
    return sessions[session_id]

@app.post("/chat", response_model=ChatResponse)
async def chat(request: ChatRequest):
    session_id = request.session_id or str(uuid.uuid4())
    rlm = get_rlm(session_id)
    response = rlm.run(request.message)
    return ChatResponse(session_id=session_id, response=response)
```

---

## –ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏–∏

### Telegram –±–æ—Ç

```python
from telegram import Update
from telegram.ext import Application, MessageHandler, filters
from rlm_toolkit import RLM
from rlm_toolkit.memory import SessionMemory

sessions = {}

def get_rlm(user_id: int) -> RLM:
    if user_id not in sessions:
        sessions[user_id] = RLM.from_openai(
            "gpt-4o",
            memory=SessionMemory(session_id=str(user_id))
        )
    return sessions[user_id]

async def handle_message(update: Update, context):
    user_id = update.effective_user.id
    text = update.message.text
    
    rlm = get_rlm(user_id)
    response = rlm.run(text)
    
    await update.message.reply_text(response)

app = Application.builder().token("your-telegram-token").build()
app.add_handler(MessageHandler(filters.TEXT, handle_message))
app.run_polling()
```

### Gradio UI

```python
import gradio as gr
from rlm_toolkit import RLM
from rlm_toolkit.memory import BufferMemory

rlm = RLM.from_openai("gpt-4o", memory=BufferMemory())

def chat(message, history):
    response = rlm.run(message)
    return response

demo = gr.ChatInterface(
    chat,
    title="RLM –ß–∞—Ç",
    description="–ß–∞—Ç —Å GPT-4o",
    examples=["–ü—Ä–∏–≤–µ—Ç!", "–û–±—ä—è—Å–Ω–∏ –∫–≤–∞–Ω—Ç–æ–≤—ã–µ –≤—ã—á–∏—Å–ª–µ–Ω–∏—è", "–ù–∞–ø–∏—à–∏ —Å—Ç–∏—Ö–æ—Ç–≤–æ—Ä–µ–Ω–∏–µ"]
)

demo.launch()
```

### Streamlit –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–µ

```python
import streamlit as st
from rlm_toolkit import RLM
from rlm_toolkit.memory import BufferMemory

st.title("ü§ñ RLM –ß–∞—Ç")

if "rlm" not in st.session_state:
    st.session_state.rlm = RLM.from_openai("gpt-4o", memory=BufferMemory())
    st.session_state.messages = []

for msg in st.session_state.messages:
    with st.chat_message(msg["role"]):
        st.write(msg["content"])

if prompt := st.chat_input("–ù–∞–ø–∏—à–∏—Ç–µ —á—Ç–æ-–Ω–∏–±—É–¥—å..."):
    st.session_state.messages.append({"role": "user", "content": prompt})
    with st.chat_message("user"):
        st.write(prompt)
    
    response = st.session_state.rlm.run(prompt)
    
    st.session_state.messages.append({"role": "assistant", "content": response})
    with st.chat_message("assistant"):
        st.write(response)
```

---

## –î–∞–ª—å–Ω–µ–π—à–∏–µ —à–∞–≥–∏

- [–¢—É—Ç–æ—Ä–∏–∞–ª—ã](../tutorials/) - –ü–æ—à–∞–≥–æ–≤—ã–µ —Ä—É–∫–æ–≤–æ–¥—Å—Ç–≤–∞
- [–ö–æ–Ω—Ü–µ–ø—Ü–∏–∏](../concepts/) - –ì–ª—É–±–æ–∫–∏–µ –ø–æ–≥—Ä—É–∂–µ–Ω–∏—è
- [How-to](../how-to/) - –ö–æ–Ω–∫—Ä–µ—Ç–Ω—ã–µ —Ä–µ—Ü–µ–ø—Ç—ã
